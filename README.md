# The ASCENT Framework for Explainable AI

This is the Github repository for the ASCENT (Ai System use Case Explanation oNTology) framework for XAI.
The ontology itself can be found in Turtle (.ttl) serialisation [here](ontology/explainability.ttl).

Paper Abstract:

> Several useful taxonomies have been published that survey the eXplainable AI (XAI) research field.
However, these taxonomies typically do not show the relation between XAI solutions and several use case aspects, such as the explanation goal or the task context.
In order to better connect the field of XAI research with concrete use cases and user needs, we designed the ASCENT (Ai System use Case Explanation oNTology) framework, which is a new ontology and corresponding metadata standard with three complementary modules for different aspects of an XAI solution: 
one for aspects of AI systems, another for use case aspects, and yet another for explanation properties.
The descriptions of XAI solutions in this framework include whether the XAI solution has a positive, negative, inconclusive or unresearched relation with use case elements.
Descriptions in ASCENT thus emphasize the (user) evaluation of XAI solutions in order to support finding validated practices for application in industry, as well as being helpful for identifying research gaps.
Describing XAI solutions according to the proposed common metadata standard is an important step towards the FAIR (Findable, Accessible, Interoperable, Reusable) usage of XAI solutions.
